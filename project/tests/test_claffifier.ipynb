{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/Walk_Video_PyTorch/project\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.9/site-packages/apex/pyprof/__init__.py:5: FutureWarning: pyprof will be removed by the end of June, 2022\n",
      "  warnings.warn(\"pyprof will be removed by the end of June, 2022\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from  models.pytorchvideo_models import WalkVideoClassificationLightningModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import get_parameters\n",
    "\n",
    "opt, unknown = get_parameters()\n",
    "opt.num_workers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = WalkVideoClassificationLightningModule(opt)\n",
    "# model = model.load_from_checkpoint(\"/workspace/Walk_Video_PyTorch/logs/resnet/0603/checkpoints/epoch=99-step=1800.ckpt\")\n",
    "model.eval()\n",
    "\n",
    "checkpoint = torch.load(\"/workspace/Walk_Video_PyTorch/logs/resnet/0708_resnet_depth50/checkpoints/epoch=51-step=3796.ckpt\")\n",
    "\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader.data_loader import WalkDataModule\n",
    "\n",
    "module = WalkDataModule(opt)\n",
    "pred_data = module.predict_dataloader()\n",
    "\n",
    "input_data = next(iter(pred_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['20190507_2_ASD_lat__V1-0033.mp4',\n",
       " '20160927_DHS_lat_V1-0054.mp4',\n",
       " '20190909_ASD_lat__V1-0002.mp4',\n",
       " '20180723_1_ASD_lat__V1-0014.mp4',\n",
       " '20210427_ASD_lat_V1-0011.mp4',\n",
       " '20210601_ASD_lat_V1-0002.mp4',\n",
       " '20180521_2_ASD_lat__V1-0045.mp4',\n",
       " '20190507_1_ASD_lat__V1-0014.mp4',\n",
       " '20180903_1_DHS_lat_V1-0037.mp4',\n",
       " '20180903_1_DHS_lat_V1-0067.mp4',\n",
       " '20180806_2_HipOA_lat_V1-0009.mp4',\n",
       " '20210812_DHS_lat_V1-0013.mp4',\n",
       " '20180109_LCS_lat_V1-0059.mp4',\n",
       " '20210309_ASD_lat__V1-0025.mp4',\n",
       " '20190917_ASD_lat__V1-0031.mp4',\n",
       " '20190507_1_ASD_lat__V1-0007.mp4']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data['video'].shape\n",
    "\n",
    "input_data[\"video_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(input_data['video'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_act = torch.nn.Softmax(dim=1)\n",
    "preds = post_act(preds)\n",
    "pred_classes = preds.topk(k=1).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "classname = {}\n",
    "\n",
    "classname[0] = 'asd'\n",
    "classname[1] = 'asd_not'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_calss = []\n",
    "\n",
    "for i in input_data['label'].tolist():\n",
    "    real_calss.append(classname[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asd',\n",
       " 'asd_not',\n",
       " 'asd',\n",
       " 'asd',\n",
       " 'asd',\n",
       " 'asd',\n",
       " 'asd',\n",
       " 'asd',\n",
       " 'asd_not',\n",
       " 'asd_not',\n",
       " 'asd_not',\n",
       " 'asd_not',\n",
       " 'asd_not',\n",
       " 'asd',\n",
       " 'asd',\n",
       " 'asd']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_calss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: asd, asd_not, asd, asd, asd, asd, asd, asd, asd_not, asd_not, asd_not, asd_not, asd_not, asd, asd, asd\n",
      "real label: asd,asd_not,asd,asd,asd,asd,asd,asd,asd_not,asd_not,asd_not,asd_not,asd_not,asd,asd,asd\n"
     ]
    }
   ],
   "source": [
    "# pred_class_names = []\n",
    "# for num in range(opt._BATCH_SIZE):\n",
    "#     for i in pred_classes[i]:\n",
    "#         pred_class_names.append(classname[int(i)])\n",
    "\n",
    "\n",
    "pred_class_names = [classname[int(i)] for i in pred_classes]\n",
    "print(\"Predicted labels: %s\" % \", \".join(pred_class_names))\n",
    "print(\"real label: %s\" % \",\".join(real_calss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class_names == real_calss"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
