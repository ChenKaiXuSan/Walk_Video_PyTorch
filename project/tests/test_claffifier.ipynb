{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/Walk_Video_PyTorch/project\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.pytorchvideo_models import WalkVideoClassificationLightningModule\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "seed_everything(42, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import get_parameters\n",
    "\n",
    "opt, unknown = get_parameters()\n",
    "opt.num_workers = 8\n",
    "opt.batch_size = 4\n",
    "opt.gpu_num = 1\n",
    "\n",
    "opt.version = '0821_2_16'\n",
    "opt.model = \"resnet\"\n",
    "opt.model_depth = 50\n",
    "\n",
    "opt.clip_duraion = 4\n",
    "opt.uniform_temporal_subsample_num = 32\n",
    "opt.version = opt.version + '_' + opt.model + '_depth' + str(opt.model_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AveragePrecision` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `AUC` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "/usr/local/lib/python3.9/dist-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `PrecisionRecallCurve` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/Walk_Video_PyTorch/logs/resnet/0821_2_16_resnet_depth50/checkpoints/epoch=73-val_loss=0.67-val_acc=0.6119.ckpt\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import get_ckpt_path\n",
    "\n",
    "model = WalkVideoClassificationLightningModule(opt)\n",
    "\n",
    "# get last ckpt path\n",
    "# ckpt_path = get_ckpt_path(opt)\n",
    "\n",
    "ckpt_path = '/workspace/Walk_Video_PyTorch/logs/resnet/0821_2_16_resnet_depth50/checkpoints/epoch=73-val_loss=0.67-val_acc=0.6119.ckpt'\n",
    "\n",
    "# model = WalkVideoClassificationLightningModule.load_from_checkpoint(ckpt_path)\n",
    "# model.load_state_dict(weight)\n",
    "model = model.load_from_checkpoint(ckpt_path)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "# clear_output()\n",
    "print(ckpt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader.data_loader import WalkDataModule\n",
    "from pytorch_lightning import loggers as pl_loggers \n",
    "\n",
    "# load test dataset \n",
    "module = WalkDataModule(opt)\n",
    "module.setup()\n",
    "test_data = module.test_dataloader()\n",
    "\n",
    "# for the tensorboard\n",
    "tb_logger = pl_loggers.TensorBoardLogger(save_dir=\"/workspace/Walk_Video_PyTorch/project/tests/logs\", name=opt.model, version=opt.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:460: UserWarning: The flag `devices=1` will be ignored, instead the device specific number 1 will be used\n",
      "  rank_zero_warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "Restoring states from the checkpoint path at /workspace/Walk_Video_PyTorch/logs/resnet/0821_2_16_resnet_depth50/checkpoints/epoch=73-val_loss=0.67-val_acc=0.6119.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n",
      "Loaded model weights from checkpoint at /workspace/Walk_Video_PyTorch/logs/resnet/0821_2_16_resnet_depth50/checkpoints/epoch=73-val_loss=0.67-val_acc=0.6119.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b1b3ef6cecf409e84dafee060ed5353",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "trainer = Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    gpus=opt.gpu_num,\n",
    "    logger=tb_logger,\n",
    "    max_epochs=1,\n",
    "    # deterministic=True,\n",
    ")\n",
    "\n",
    "trainer.test(dataloaders=module, model=model, ckpt_path=ckpt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = next(iter(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data['video'].shape\n",
    "\n",
    "input_data[\"video_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(input_data['video'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_label = input_data['label']\n",
    "pred_label = preds\n",
    "\n",
    "real_label, pred_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import sigmoid, tanh, softmax\n",
    "\n",
    "sigmoid(pred_label), tanh(pred_label), softmax(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label_softmax = torch.softmax(pred_label, dim =-1)\n",
    "pred_label_softmax.shape, real_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import HingeEmbeddingLoss, CrossEntropyLoss, BCEWithLogitsLoss\n",
    "\n",
    "hingeloss = HingeEmbeddingLoss(reduction='mean')\n",
    "crossloss = CrossEntropyLoss()\n",
    "bceloss = BCEWithLogitsLoss()\n",
    "\n",
    "crossloss(pred_label_softmax, real_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.topk(k=1).indices, real_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import softmax\n",
    "\n",
    "\n",
    "pred_chagne = softmax(preds, dim=-1)\n",
    "pred_chagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.metrics import get_Accuracy\n",
    "\n",
    "accuracy = get_Accuracy()\n",
    "\n",
    "accuracy(pred_chagne, input_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classname = {}\n",
    "\n",
    "classname[0] = 'asd'\n",
    "classname[1] = 'asd_not'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_calss = []\n",
    "\n",
    "for i in input_data['label'].tolist():\n",
    "    real_calss.append(classname[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_calss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_class_names = []\n",
    "# for num in range(opt._BATCH_SIZE):\n",
    "#     for i in pred_classes[i]:\n",
    "#         pred_class_names.append(classname[int(i)])\n",
    "\n",
    "\n",
    "pred_class_names = [classname[int(i)] for i in pred_classes]\n",
    "print(\"Predicted labels: %s\" % \", \".join(pred_class_names))\n",
    "print(\"real label: %s\" % \",\".join(real_calss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class_names == real_calss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "\n",
    "for i in range(len(real_calss)):\n",
    "    if pred_class_names[i] == real_calss[i]:\n",
    "        result.append(\"true\")\n",
    "    else:\n",
    "        result.append(\"false\")\n",
    "\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
