{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/Walk_Video_PyTorch/project\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.pytorchvideo_models import WalkVideoClassificationLightningModule\n",
    "from pytorch_lightning import Trainer\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_lightning import seed_everything\n",
    "\n",
    "seed_everything(42, workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import get_parameters\n",
    "\n",
    "opt, unknown = get_parameters()\n",
    "opt.num_workers = 8\n",
    "opt.batch_size = 32\n",
    "opt.gpu_num = 1\n",
    "opt.model = \"x3d\"\n",
    "opt.model_depth = 50\n",
    "opt.clip_duarion = 1\n",
    "opt.version = '0724' + '_' + opt.model + '_depth' + str(opt.model_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspace/Walk_Video_PyTorch/logs/x3d/0724_x3d_depth50/checkpoints/epoch=99-step=9988.ckpt\n"
     ]
    }
   ],
   "source": [
    "from utils.utils import get_ckpt_path\n",
    "\n",
    "model = WalkVideoClassificationLightningModule(opt)\n",
    "\n",
    "# get last ckpt path\n",
    "ckpt_path = get_ckpt_path(opt)\n",
    "\n",
    "\n",
    "model = model.load_from_checkpoint(ckpt_path)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "clear_output()\n",
    "print(ckpt_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:460: UserWarning: The flag `devices=1` will be ignored, instead the device specific number 1 will be used\n",
      "  rank_zero_warn(\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d19258930a14b2c81193f0f8302dd14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 19. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 27. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 21. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 12. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 24. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 11. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 2. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/utilities/data.py:72: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 1. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_acc_epoch       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.20969441533088684    </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      test_loss_epoch      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     1.087226390838623     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_acc_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.20969441533088684   \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     test_loss_epoch     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    1.087226390838623    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'test_loss_epoch': 1.087226390838623, 'test_acc_epoch': 0.20969441533088684}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataloader.data_loader import WalkDataModule\n",
    "from pytorch_lightning import loggers as pl_loggers \n",
    "\n",
    "# load test dataset \n",
    "module = WalkDataModule(opt)\n",
    "module.setup()\n",
    "test_data = module.test_dataloader()\n",
    "\n",
    "# for the tensorboard\n",
    "tb_logger = pl_loggers.TensorBoardLogger(save_dir=\"/workspace/Walk_Video_PyTorch/project/tests/logs\", name=opt.model, version=opt.version)\n",
    "\n",
    "trainer = Trainer(\n",
    "    accelerator=\"auto\",\n",
    "    devices=1,\n",
    "    gpus=opt.gpu_num,\n",
    "    logger=tb_logger,\n",
    "    max_epochs=1,\n",
    "    deterministic=True,\n",
    ")\n",
    "\n",
    "trainer.test(dataloaders=module, model=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.validate(model=model, dataloaders=module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = next(iter(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4139,  0.8608,  0.8478,  0.8235,  0.8887,  0.9493,  0.8629,  0.9736,\n",
       "         0.9662,  1.2505,  1.6023,  1.2303, -0.2963, -0.2416, -0.1844, -0.1351,\n",
       "        -0.1176, -0.1176, -0.0566,  0.0990,  1.3954,  1.6166,  2.0716,  2.3634,\n",
       "         2.4096,  2.4096,  2.4096,  1.5312, -0.0915, -0.7800, -1.1871, -0.4486,\n",
       "         0.6138,  2.4096,  2.3334,  1.6189,  1.5599,  2.2723,  0.3523,  1.9796,\n",
       "         1.3100,  1.2151,  1.5797,  2.4287,  2.4202,  2.4096,  2.4096,  2.4096,\n",
       "         2.4096,  2.4096,  2.4019,  0.8952,  0.3395,  0.3018,  0.2789,  0.2832,\n",
       "         0.2484,  0.2484,  0.1786,  0.1786,  0.1786,  0.1786,  0.1612,  0.1612,\n",
       "         0.1612,  0.1612,  0.1612,  0.2179,  0.1786,  0.1786,  0.1961,  0.2033,\n",
       "         0.0802,  0.0103,  0.1828,  0.2783,  0.8648,  0.8685,  0.1737,  0.1379,\n",
       "         0.1400,  0.1743,  0.1961,  0.1307,  0.2660,  0.0287,  0.0246,  0.0510,\n",
       "         0.0266,  0.0438,  0.1120,  0.1786,  0.1786,  0.1786,  0.2309,  0.2431,\n",
       "         0.2702,  0.2832,  0.2832,  0.2832,  0.2832,  0.3007,  0.3181,  0.3007,\n",
       "         0.3007,  0.3007,  0.3007,  0.3007,  0.3007,  0.3007,  0.3007,  0.3007,\n",
       "         0.3007,  0.3007,  0.3007,  0.3355,  0.3181,  0.3181,  0.3181,  0.3181,\n",
       "         0.3181,  0.3181,  0.3181,  0.3181,  0.3181,  0.3181,  0.3181,  0.3181,\n",
       "         0.3137,  0.2832,  0.2900,  0.3118,  0.3007,  0.3007,  0.3007,  0.3007,\n",
       "         0.3007,  0.3007,  0.1961,  0.1961,  0.1961,  0.2620,  0.3885,  2.4132,\n",
       "         2.4096,  2.4096,  2.4096,  2.4096,  2.4096,  2.4096,  2.4096,  2.4096,\n",
       "         2.4183,  0.6319,  0.5172,  0.4653,  0.3772,  0.3772,  0.3965,  0.4041,\n",
       "         0.3355,  0.3355,  0.3704,  0.3007,  0.2658,  0.2484,  0.2484,  0.2309,\n",
       "         0.2266,  0.1786,  0.1743,  0.1264,  0.1455,  0.1264,  0.1089,  0.0436,\n",
       "         0.0174, -0.0131, -0.0479, -0.0654, -0.0828, -0.0415, -0.1179,  0.5430,\n",
       "         0.5926,  0.5098,  0.0703,  0.3007,  0.3529,  0.3529,  0.4107,  0.3448,\n",
       "         0.3834,  0.3929,  0.4619,  0.4139,  0.4774,  0.3868,  0.0095,  0.2870,\n",
       "         0.3355,  0.2456,  0.3015,  0.3077,  0.2776,  0.2053,  0.2513,  0.1848,\n",
       "         0.2100,  0.1735,  0.0500,  0.0310, -0.1152,  0.3268,  0.3529,  0.3834,\n",
       "         0.3878,  0.4090,  0.4401,  0.4924,  0.5272,  0.5255,  0.5579,  0.6504,\n",
       "         0.6718,  0.8285,  1.0062,  1.5208,  2.4444,  2.4096,  2.4096,  2.4096,\n",
       "         2.4096,  2.4096,  2.4096,  2.4096,  2.4096,  2.4270,  2.4198,  1.0341,\n",
       "         0.5399,  0.3947,  0.1625, -0.5304, -0.4914, -0.4018, -0.5086, -1.2994,\n",
       "        -1.4946, -1.4984, -1.2286, -0.3962, -0.2575, -0.1437, -0.0589, -0.0356])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data['video'].shape\n",
    "\n",
    "input_data[\"video_name\"]\n",
    "\n",
    "input_data['video'][0][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        1, 1, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(input_data['video'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_act = torch.nn.Softmax(dim=1)\n",
    "preds = post_act(preds)\n",
    "pred_classes = preds.topk(k=1).indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6135, 0.3865],\n",
       "        [0.6135, 0.3865],\n",
       "        [0.6135, 0.3865],\n",
       "        [0.3865, 0.6135],\n",
       "        [0.3865, 0.6135],\n",
       "        [0.3867, 0.6133],\n",
       "        [0.3865, 0.6135],\n",
       "        [0.3865, 0.6135],\n",
       "        [0.3865, 0.6135],\n",
       "        [0.3865, 0.6135],\n",
       "        [0.3865, 0.6135],\n",
       "        [0.6135, 0.3865],\n",
       "        [0.6134, 0.3866],\n",
       "        [0.6135, 0.3865],\n",
       "        [0.3865, 0.6135],\n",
       "        [0.3865, 0.6135],\n",
       "        [0.3865, 0.6135],\n",
       "        [0.3865, 0.6135],\n",
       "        [0.3866, 0.6134],\n",
       "        [0.3876, 0.6124],\n",
       "        [0.3865, 0.6135],\n",
       "        [0.3865, 0.6135],\n",
       "        [0.3865, 0.6135],\n",
       "        [0.6135, 0.3865],\n",
       "        [0.6135, 0.3865],\n",
       "        [0.6135, 0.3865],\n",
       "        [0.6135, 0.3865],\n",
       "        [0.3865, 0.6135],\n",
       "        [0.3865, 0.6135],\n",
       "        [0.3865, 0.6135],\n",
       "        [0.3865, 0.6135],\n",
       "        [0.3865, 0.6135]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import softmax\n",
    "\n",
    "\n",
    "pred_chagne = softmax(preds, dim=-1)\n",
    "pred_chagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0312)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.metrics import get_Accuracy\n",
    "\n",
    "accuracy = get_Accuracy()\n",
    "\n",
    "accuracy(pred_chagne, input_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "classname = {}\n",
    "\n",
    "classname[0] = 'asd'\n",
    "classname[1] = 'asd_not'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_calss = []\n",
    "\n",
    "for i in input_data['label'].tolist():\n",
    "    real_calss.append(classname[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asd_not',\n",
       " 'asd_not',\n",
       " 'asd_not',\n",
       " 'asd',\n",
       " 'asd',\n",
       " 'asd',\n",
       " 'asd',\n",
       " 'asd_not',\n",
       " 'asd',\n",
       " 'asd',\n",
       " 'asd',\n",
       " 'asd_not',\n",
       " 'asd_not',\n",
       " 'asd_not',\n",
       " 'asd',\n",
       " 'asd',\n",
       " 'asd',\n",
       " 'asd',\n",
       " 'asd',\n",
       " 'asd',\n",
       " 'asd',\n",
       " 'asd',\n",
       " 'asd',\n",
       " 'asd_not',\n",
       " 'asd_not',\n",
       " 'asd_not',\n",
       " 'asd_not',\n",
       " 'asd',\n",
       " 'asd',\n",
       " 'asd',\n",
       " 'asd',\n",
       " 'asd']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_calss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels: asd, asd, asd, asd_not, asd_not, asd_not, asd_not, asd_not, asd_not, asd_not, asd_not, asd, asd, asd, asd_not, asd_not, asd_not, asd_not, asd_not, asd_not, asd_not, asd_not, asd_not, asd, asd, asd, asd, asd_not, asd_not, asd_not, asd_not, asd_not\n",
      "real label: asd_not,asd_not,asd_not,asd,asd,asd,asd,asd_not,asd,asd,asd,asd_not,asd_not,asd_not,asd,asd,asd,asd,asd,asd,asd,asd,asd,asd_not,asd_not,asd_not,asd_not,asd,asd,asd,asd,asd\n"
     ]
    }
   ],
   "source": [
    "# pred_class_names = []\n",
    "# for num in range(opt._BATCH_SIZE):\n",
    "#     for i in pred_classes[i]:\n",
    "#         pred_class_names.append(classname[int(i)])\n",
    "\n",
    "\n",
    "pred_class_names = [classname[int(i)] for i in pred_classes]\n",
    "print(\"Predicted labels: %s\" % \", \".join(pred_class_names))\n",
    "print(\"real label: %s\" % \",\".join(real_calss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_class_names == real_calss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['false',\n",
       " 'false',\n",
       " 'false',\n",
       " 'false',\n",
       " 'false',\n",
       " 'false',\n",
       " 'false',\n",
       " 'true',\n",
       " 'false',\n",
       " 'false',\n",
       " 'false',\n",
       " 'false',\n",
       " 'false',\n",
       " 'false',\n",
       " 'false',\n",
       " 'false',\n",
       " 'false',\n",
       " 'false',\n",
       " 'false',\n",
       " 'false',\n",
       " 'false',\n",
       " 'false',\n",
       " 'false',\n",
       " 'false',\n",
       " 'false',\n",
       " 'false',\n",
       " 'false',\n",
       " 'false',\n",
       " 'false',\n",
       " 'false',\n",
       " 'false',\n",
       " 'false']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "for i in range(len(real_calss)):\n",
    "    if pred_class_names[i] == real_calss[i]:\n",
    "        result.append(\"true\")\n",
    "    else:\n",
    "        result.append(\"false\")\n",
    "\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
